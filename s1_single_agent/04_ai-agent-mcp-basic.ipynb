{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3eda57",
   "metadata": {},
   "source": [
    "# Quick Start: Azure AI Foundry SDK + MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3893bdf",
   "metadata": {},
   "source": [
    "### Step 1: Import the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af813c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Endpoint: https://ai-foundry-hackathon-team55.services.ai.azure.com/api/projects/ai-project-hackathon-team55\n",
      "Model Deployment Name: gpt-4o\n",
      "Current Python executable: c:\\Users\\Yu-Hong (Frank) Lin\\Repos\\azure-ai-agent-workshop\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    " \n",
    "# --- Azure AI Foundry SDK for AI agents and services ---\n",
    "from azure.ai.agents.models import MessageTextContent, ListSortOrder\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Load the environment variables from a .env file\n",
    "if not load_dotenv('../.env', override=True):\n",
    "    load_dotenv(override=True)\n",
    "print(f\"Project Endpoint: {os.getenv('AZURE_AI_AGENT_ENDPOINT')}\")\n",
    "print(f\"Model Deployment Name: {os.getenv('AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME')}\")\n",
    "\n",
    "# Check the current working Python execution environment\n",
    "print(f\"Current Python executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32615c8",
   "metadata": {},
   "source": [
    "### Step 2: create AI Project Client and create an Azure AI Foundry Agent\n",
    "##### *server_labelis* a unique name you provide for the MCP server within the same Foundry Agent\n",
    "##### *server_url* is the url of the MCP server\n",
    "##### *require_approval* supports never"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d089a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_mU2YbYvuzegm8zDveobWtyBB\n"
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_AGENT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\"], \n",
    "        name=\"04_my github agent\", \n",
    "        instructions=\"You are a helpful assistant. Use the tools provided to answer the user's questions. Be sure to cite your sources.\",\n",
    "        tools= [\n",
    "            {\n",
    "                \"type\": \"mcp\",\n",
    "                \"server_label\": \"repo\",\n",
    "                \"server_url\": \"https://gitmcp.io/ownway22/azure-ai-agent\",\n",
    "            }\n",
    "        ],\n",
    "        tool_resources=None\n",
    "    )\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a6763",
   "metadata": {},
   "source": [
    "### Step 3: Create a Thread, Message and Run\n",
    "##### Within the Run, you can pass custom headers and use the server_label you provided to map to the specific MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebd3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, thread ID: thread_uxFnPHc2p60pvrZZclZR5TvQ\n",
      "Created message, message ID: msg_M6yUJ269oBTDBqHSdFOTm8Ph\n"
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_AGENT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=\"who is the author of this repository?\",\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731b67d",
   "metadata": {},
   "source": [
    "### Step 4: Execute the Run and retrieve Message\n",
    "##### You can use run_step to get more details on tool inputs and tool outputs. Once the run is complete, you can retrieve message back from the Foundry Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02be9450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "Run step: step_mgGkeTjKkEVGDqEkvUoRVF7t, status: RunStepStatus.COMPLETED, type: RunStepType.MESSAGE_CREATION\n",
      "MessageRole.USER: who is the author of this repository?\n",
      "MessageRole.AGENT: The repository \"ownway22/azure-ai-agent\" is authored by GitHub user **ownway22**. You can identify the author as the GitHub username associated with the repository.\n"
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_AGENT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    # Poll the run as long as run status is queued or in progress\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        # Wait for a second\n",
    "        time.sleep(1)\n",
    "        run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "        print(f\"Run status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run error: {run.last_error}\")\n",
    "\n",
    "    run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    for step in run_steps:\n",
    "        print(f\"Run step: {step.id}, status: {step.status}, type: {step.type}\")\n",
    "        if step.type == \"tool_calls\":\n",
    "            print(f\"Tool call details:\")\n",
    "            for tool_call in step.step_details.tool_calls:\n",
    "                print(json.dumps(tool_call.as_dict(), indent=2))\n",
    "\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "    for data_point in messages:\n",
    "        last_message_content = data_point.content[-1]\n",
    "        if isinstance(last_message_content, MessageTextContent):\n",
    "            print(f\"{data_point.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a604a",
   "metadata": {},
   "source": [
    "### Step 5: Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_AGENT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(f\"Deleted agent, agent ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014f4cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### Reference: [Announcing Model Context Protocol Support (preview) in Azure AI Foundry Agent Service | Azure AI Foundry Blog](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
